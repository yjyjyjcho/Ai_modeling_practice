{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled21.ipynb","provenance":[],"authorship_tag":"ABX9TyMdTyZEoYhtM59OFxsefbwb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sK0-lJzHcAO9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ca58038f-0eb0-4b81-d588-cbe99c03d3f2","executionInfo":{"status":"ok","timestamp":1591764833477,"user_tz":-540,"elapsed":3134,"user":{"displayName":"우렉마지노","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-O47QQyryHBGXIfhftqjtuEUb4byCYi_4CRFH7Q=s64","userId":"07446739532334297381"}}},"source":["from keras.layers import Dense,Dropout\n","from keras.layers.recurrent import LSTM,GRU\n","from keras.models import Input,Sequential,Model\n","from keras.optimizers import Adam,Nadam\n","\n","def build_simple_rnn_model(timestep,input_dim,output_dim,dropout=0.4,lr=0.001):\n","    input = Input((timestep,input_dim))\n","    # LSTM, Single\n","    output = LSTM(50,return_sequences=False)(input)\n","    # for _ in range(1):\n","    #     output = LSTM(32,return_sequences=True)(output)\n","    # output = LSTM(50,return_sequences=False)(output)\n","    output = Dropout(dropout)(output)\n","    output = Dense(output_dim)(output)\n","\n","    model =  Model(inputs=input,outputs=output)\n","\n","    optimizer = Adam(lr=lr)\n","\n","    model.compile(loss='mae',optimizer=optimizer,metrics=['mse'])\n","\n","    return model\n","\n","from keras.layers import merge\n","from keras.layers.merge import add,concatenate\n","from keras.layers.convolutional import Conv2D,MaxPooling2D,ZeroPadding2D,AveragePooling2D,Conv1D,MaxPooling1D\n","from keras.layers.core import Dense,Activation,Flatten,Dropout,Masking\n","from keras.layers.normalization import BatchNormalization\n","from keras.models import Model\n","from keras.layers import Input,TimeDistributed\n","from keras.layers.recurrent import LSTM\n","\n","# looking for stanfordmlgroup.github.io/projects/ecg/ for detail\n","\n","def first_block(tensor_input,filters,kernel_size=3,pooling_size=1,dropout=0.5):\n","    k1,k2 = filters\n","\n","    out = Conv1D(k1,1,padding='same')(tensor_input)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dropout(dropout)(out)\n","    out = Conv1D(k2,kernel_size,strides=2,padding='same')(out)\n","\n","\n","    pooling = MaxPooling1D(pooling_size,strides=2,padding='same')(tensor_input)\n","\n","\n","    # out = merge([out,pooling],mode='sum')\n","    out = add([out,pooling])\n","    return out\n","\n","def repeated_block(x,filters,kernel_size=3,pooling_size=1,dropout=0.5):\n","\n","    k1,k2 = filters\n","\n","\n","    out = BatchNormalization()(x)\n","    out = Activation('relu')(out)\n","    out = Conv1D(k1,kernel_size,padding='same')(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dropout(dropout)(out)\n","    out = Conv1D(k2,kernel_size,strides=2,padding='same')(out)\n","\n","\n","    pooling = MaxPooling1D(pooling_size,strides=2,padding='same')(x)\n","\n","    out = add([out, pooling])\n","\n","    #out = merge([out,pooling])\n","    return out\n","\n","def first_rul_block(tensor_input,filters,kernel_size=3,pooling_size=1,dropout=0.5):\n","    k1,k2 = filters\n","\n","    out = Conv1D(k1,1,padding='same')(tensor_input)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dropout(dropout)(out)\n","    out = Conv1D(k2,kernel_size,strides=2,padding='same')(out)\n","\n","\n","    pooling = MaxPooling1D(pooling_size,strides=2,padding='same')(tensor_input)\n","\n","\n","    # out = merge([out,pooling],mode='sum')\n","    out = add([out,pooling])\n","    return out\n","\n","def repeated_rul_block(x,filters,kernel_size=5,pooling_size=1,dropout=0.5):\n","\n","    k1,k2 = filters\n","\n","\n","    out = BatchNormalization()(x)\n","    out = Activation('relu')(out)\n","    out = Conv1D(k1,kernel_size,padding='same')(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dropout(dropout)(out)\n","    out = Conv1D(k2,kernel_size,strides=3,padding='same')(out)\n","\n","\n","    pooling = MaxPooling1D(pooling_size,strides=3,padding='same')(x)\n","\n","    out = add([out, pooling])\n","\n","    #out = merge([out,pooling])\n","    return out\n","\n","def build_multi_input_main_residual_network(batch_size,\n","                                a2_time_step,\n","                                d2_time_step,\n","                                d1_time_step,\n","                                input_dim,\n","                                output_dim,\n","                                loop_depth=15,\n","                                dropout=0.5):\n","    '''\n","    a multiple residual network for wavelet transformation\n","    :param batch_size: as you might see\n","    :param a2_time_step: a2_size\n","    :param d2_time_step: d2_size\n","    :param d1_time_step: d1_size\n","    :param input_dim: input_dim\n","    :param output_dim: output_dim\n","    :param loop_depth: depth of residual network\n","    :param dropout: rate of dropout\n","    :return: \n","    '''\n","    a2_inp = Input(shape=(a2_time_step,input_dim),name='a2')\n","    d2_inp = Input(shape=(d2_time_step,input_dim),name='d2')\n","    d1_inp = Input(shape=(d1_time_step,input_dim),name='a1')\n","\n","    out = concatenate([a2_inp,d2_inp,d1_inp],axis=1)\n","\n","\n","\n","    out = Conv1D(128,5)(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","\n","    out = first_block(out,(64,128),dropout=dropout)\n","\n","    for _ in range(loop_depth):\n","        out = repeated_block(out,(64,128),dropout=dropout)\n","\n","    # add flatten\n","    out = Flatten()(out)\n","\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dense(output_dim)(out)\n","\n","    model = Model(inputs=[a2_inp,d2_inp,d1_inp],outputs=[out])\n","\n","    model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n","    return model\n","\n","def build_rul_multi_input_main_residual_network(batch_size,\n","                                a2_time_step,\n","                                d2_time_step,\n","                                d1_time_step,\n","                                input_dim,\n","                                output_dim,\n","                                loop_depth=15,\n","                                dropout=0.5):\n","    '''\n","    a multiple residual network for wavelet transformation\n","    :param batch_size: as you might see\n","    :param a2_time_step: a2_size\n","    :param d2_time_step: d2_size\n","    :param d1_time_step: d1_size\n","    :param input_dim: input_dim\n","    :param output_dim: output_dim\n","    :param loop_depth: depth of residual network\n","    :param dropout: rate of dropout\n","    :return:\n","    '''\n","    a2_inp = Input(shape=(a2_time_step,input_dim),name='a2')\n","    d2_inp = Input(shape=(d2_time_step,input_dim),name='d2')\n","    d1_inp = Input(shape=(d1_time_step,input_dim),name='a1')\n","\n","    out = concatenate([a2_inp,d2_inp,d1_inp],axis=1)\n","\n","\n","\n","    out = Conv1D(128,5)(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","\n","    out = first_rul_block(out,(64,128),dropout=dropout)\n","\n","    for _ in range(loop_depth):\n","        out = repeated_rul_block(out,(64,128),dropout=dropout)\n","\n","    # add flatten\n","    out = Flatten()(out)\n","\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dense(output_dim)(out)\n","\n","    model = Model(inputs=[a2_inp,d2_inp,d1_inp],outputs=[out])\n","\n","    model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n","    return model\n","\n","\n","def first_2d_block(tensor_input,filters,kernel_size=3,pooling_size=2,dropout=0.5):\n","    k1,k2 = filters\n","\n","    out = Conv2D(k1,1,padding='same',data_format='channels_last')(tensor_input)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dropout(dropout)(out)\n","    out = Conv2D(k2,kernel_size,2,padding='same',data_format='channels_last')(out)\n","\n","\n","    pooling = MaxPooling2D(pooling_size,padding='same',data_format='channels_last')(tensor_input)\n","\n","\n","    # out = merge([out,pooling],mode='sum')\n","    out = add([out,pooling])\n","    return out\n","\n","def repeated_2d_block(x,filters,kernel_size=3,pooling_size=1,dropout=0.5):\n","\n","    k1,k2 = filters\n","\n","\n","    out = BatchNormalization()(x)\n","    out = Activation('relu')(out)\n","    out = Conv2D(k1,kernel_size,2,padding='same',data_format='channels_last')(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dropout(dropout)(out)\n","    out = Conv2D(k2,kernel_size,2,padding='same',data_format='channels_last')(out)\n","\n","\n","    pooling = MaxPooling2D(pooling_size,padding='same',data_format='channels_last')(x)\n","\n","    out = add([out, pooling])\n","\n","    #out = merge([out,pooling])\n","    return out\n","\n","def build_2d_main_residual_network(batch_size,\n","                                width,\n","                                height,\n","                                channel_size,\n","                                output_dim,\n","                                loop_depth=15,\n","                                dropout=0.3):\n","    inp = Input(shape=(width,height,channel_size))\n","\n","    # add mask for filter invalid data\n","    out = TimeDistributed(Masking(mask_value=0))(inp)\n","\n","\n","    out = Conv2D(128,5,data_format='channels_last')(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","\n","    out = first_2d_block(out,(64,128),dropout=dropout)\n","\n","    for _ in range(loop_depth):\n","        out = repeated_2d_block(out,(64,128),dropout=dropout)\n","\n","    # add flatten\n","    out = Flatten()(out)\n","\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dense(output_dim)(out)\n","\n","    model = Model(inp,out)\n","\n","    model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n","    return model\n","\n","\n","def build_main_residual_network_with_lstm(batch_size,\n","                                time_step,\n","                                input_dim,\n","                                output_dim,\n","                                loop_depth=15,\n","                                rnn_layer_num = 2,\n","                                dropout=0.3):\n","\n","\n","    inp = Input(shape=(time_step,input_dim))\n","\n","\n","\n","    # add mask for filter invalid data\n","    out = TimeDistributed(Masking(mask_value=0))(inp)\n","\n","    # add LSTM module\n","    for _ in range(rnn_layer_num):\n","        out = LSTM(128,return_sequences=True)(out)\n","\n","\n","\n","    out = Conv1D(128,5)(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","\n","    out = first_block(out,(64,128),dropout=dropout)\n","\n","    for _ in range(loop_depth):\n","        out = repeated_block(out,(64,128),dropout=dropout)\n","\n","    # add flatten\n","    out = Flatten()(out)\n","\n","    out = BatchNormalization()(out)\n","    out = Activation('relu')(out)\n","    out = Dense(output_dim)(out)\n","\n","    model = Model(inp,out)\n","\n","    model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n","    return model\n","\n","  "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4GkvZCHakq9q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":336},"outputId":"7a9d1466-6595-4125-b72f-79358131b21c","executionInfo":{"status":"error","timestamp":1591764914570,"user_tz":-540,"elapsed":1084,"user":{"displayName":"우렉마지노","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-O47QQyryHBGXIfhftqjtuEUb4byCYi_4CRFH7Q=s64","userId":"07446739532334297381"}}},"source":["from keras.utils import plot_model\n","plot_model(build_simple_rnn_model, to_file='model.png')"],"execution_count":3,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8c878475cd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_simple_rnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Create graph nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute '_layers'"]}]},{"cell_type":"code","metadata":{"id":"W4tX6Uq7k0Zv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}