{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled5.ipynb","provenance":[],"authorship_tag":"ABX9TyO0WHGu7yZWBTA0cI6GY337"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xKl8kc_-Vn4J","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","hello = tf.constant('Hello, TensorFlow!')\n","sess = tf.Session()\n","print(sess.run(hello))\n","a = tf.constant(10)\n","b= tf.constant(32)\n","print(sess.run(a+b))\n","exit()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tieDSpbuXRO1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"9a31beb3-7be0-4561-c2de-3c745ffeeaf2","executionInfo":{"status":"ok","timestamp":1579683409422,"user_tz":-540,"elapsed":1236,"user":{"displayName":"우렉마지노","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD5mJV8Ktjt0PxFe33dyY-FG36dQux15SoHKmMnkQ=s64","userId":"07446739532334297381"}}},"source":["3**2\n","\n","type(\"hello\")\n","x=10\n","print(x)\n","y=3.14\n","type(x*y)\n","a=[1,2,3,4,5]\n","print(a)\n","len(a)\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["10\n","[1, 2, 3, 4, 5]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"VRbxxYQYhxTc","colab_type":"code","colab":{}},"source":["\n","\n","def ANN_models_func(Nin, Nh, Nout):\n","    x = layers.Input(shape=(Nin,))\n","    h = layers.Activation('relu')(layers.Dense(Nh)(x))\n","    y = layers.Activation('softmax')(layers.Dense(Nout)(h))\n","    model = models.Model(x, y)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","\n","def ANN_seq_func(Nin, Nh, Nout):\n","    model = models.Sequential()\n","    model.add(layers.Dense(Nh, activation='relu', input_shape=(Nin,)))\n","    model.add(layers.Dense(Nout, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","\n","class ANN_models_class(models.Model):\n","    def __init__(self, Nin, Nh, Nout):\n","        # Prepare network layers and activate functions\n","        hidden = layers.Dense(Nh)\n","        output = layers.Dense(Nout)\n","        relu = layers.Activation('relu')\n","        softmax = layers.Activation('softmax')\n","\n","        # Connect network elements\n","        x = layers.Input(shape=(Nin,))\n","        h = relu(hidden(x))\n","        y = softmax(output(h))\n","\n","        super().__init__(x, y)\n","        self.compile(loss='categorical_crossentropy',\n","                     optimizer='adam', metrics=['accuracy'])\n","\n","\n","class ANN_seq_class(models.Sequential):\n","    def __init__(self, Nin, Nh, Nout):\n","        super().__init__()\n","        self.add(layers.Dense(Nh, activation='relu', input_shape=(Nin,)))\n","        self.add(layers.Dense(Nout, activation='softmax'))\n","        self.compile(loss='categorical_crossentropy',\n","                     optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jb7pevV7h6lV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"55464d7b-d484-4a5a-fcd6-743f5e24583e","executionInfo":{"status":"error","timestamp":1579687296089,"user_tz":-540,"elapsed":1212,"user":{"displayName":"우렉마지노","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD5mJV8Ktjt0PxFe33dyY-FG36dQux15SoHKmMnkQ=s64","userId":"07446739532334297381"}}},"source":["##############################################\n","# Modeling\n","##############################################\n","import keras\n","from tensorflow.keras import backend\n","from tensorflow.keras import layers, models\n","\n","class CNN(models.Sequential):\n","    def __init__(self, input_shape, num_classes):\n","        super().__init__()\n","\n","        self.add(layers.Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","        self.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","        self.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","        self.add(layers.Dropout(0.25))\n","        self.add(layers.Flatten())\n","        self.add(layers.Dense(128, activation='relu'))\n","        self.add(layers.Dropout(0.5))\n","        self.add(layers.Dense(num_classes, activation='softmax'))\n","\n","        self.compile(loss=keras.losses.categorical_crossentropy,\n","                      optimizer='rmsprop',\n","                      metrics=['accuracy'])\n","\n","\n","\n","##############################################\n","# Data\n","##############################################\n","import numpy as np\n","from tensorflow.keras import datasets  # mnist\n","from tensorflow.keras import utils  # to_categorical\n","\n","class DATA():\n","  def __init__(self):\n","         num_classes = 10\n","            \n","         (X_train, Y_train), (X_test, Y_test) = datasets.mnist.load_data()\n","         img_rows, img_cols = X_train.shape[1:]\n","\n","         if backend.image_data_format() == 'channels_first':\n","            X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n","            X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n","            input_shape = (1, img_rows, img_cols)\n","         else:\n","              X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n","              X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n","              input_shape = (img_rows, img_cols, 1)\n","           \n","\n","           X_train = X_train.astype('float32')\n","           X_test = X_test.astype('float32')\n","           X_train /= 255\n","           X_test /= 255\n","\n","           Y_train = utils.to_categorical(y_train, num_classes)\n","           Y_test = utils.to_categorical(y_test, num_classes)\n","\n","   ## X_train = X_train / 255.0\n","   ## X_test = X_test / 255.0\n","\n","   ## return (X_train, Y_train), (X_test, Y_test)\n","\n","            self.input_shape = input_shape\n","            self.num_classes = num_classes\n","            self.X_train, self.Y_train = X_train, X_train\n","            self.X_test, self.Y_test = Y_test, Y_test\n","\n","##############################################\n","# Plotting\n","##############################################\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_acc(history, title=None):\n","    # summarize history for accuracy\n","    if not isinstance(history, dict):\n","        history = history.history\n","\n","    plt.plot(history['acc'])\n","    plt.plot(history['val_acc'])\n","    if title is not None:\n","        plt.title(title)\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training', 'Verification'], loc=0)\n","    # plt.show()\n","\n","\n","def plot_loss(history, title=None):\n","    # summarize history for loss\n","    if not isinstance(history, dict):\n","        history = history.history\n","\n","    plt.plot(history['loss'])\n","    plt.plot(history['val_loss'])\n","    if title is not None:\n","        plt.title(title)\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training', 'Verification'], loc=0)\n","    plt.show()\n","\n","\n","##############################################\n","# Main\n","##############################################\n","def main():\n","   \n","\n","    # model = ANN_models_func(Nin, Nh, Nout)\n","    # model = ANN_models_class(Nin, Nh, Nout)\n","    # model = ANN_seq_class(Nin, Nh, Nout)\n","    # (X_train, Y_train), (X_test, Y_test) = Data_func()\n","\n","    data = DATA()\n","    model = CNN(data.input_shape, data.num_classes)\n","\n","\n","    ##############################################\n","    # Training\n","    ##############################################\n","    history = model.fit(X_train, Y_train, epochs=10, batch_size=128, validation_split=0.2)\n","    performace_test = model.evaluate(X_test, Y_test, batch_size=128, verbose=0)\n","    score = model.evaluate(data.X_test, data.Y_test)\n","    print()\n","    print('Test loss:', score[0])\n","    print('Test accuracy:', score[1])\n","\n","    plot_loss(history)\n","    plt.show()\n","    plot_acc(history)\n","    plt.show()\n","\n","\n","# Run code\n","if __name__ == '__main__':\n","    main()"],"execution_count":37,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-29085486b07f>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    X_train = X_train.astype('float32')\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"]}]},{"cell_type":"code","metadata":{"id":"JMOUNYlftwzI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a59969db-24cc-4e80-ba7b-65c1ee1fd71e","executionInfo":{"status":"ok","timestamp":1579687549762,"user_tz":-540,"elapsed":1382,"user":{"displayName":"우렉마지노","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD5mJV8Ktjt0PxFe33dyY-FG36dQux15SoHKmMnkQ=s64","userId":"07446739532334297381"}}},"source":["from tensorflow import keras\n","keras.__version__"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.2.4-tf'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"kMUTJOoAx3QE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":244},"outputId":"d073c5f0-b127-4dda-a21e-ebf41b75df42","executionInfo":{"status":"error","timestamp":1579691034552,"user_tz":-540,"elapsed":1644,"user":{"displayName":"우렉마지노","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD5mJV8Ktjt0PxFe33dyY-FG36dQux15SoHKmMnkQ=s64","userId":"07446739532334297381"}}},"source":["from keras.datasets import mnist\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","import matplotlib.pyplot as plt\n","import os\n","import numpy\n","\n","MODEL_SAVE_FOLDER_PATH = './model/'\n","\n","if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","\n","model_path = MODEL_SAVE_FOLDER_PATH + 'mnist-' + '{epoch:02d}-{val_loss:.4f}.hdf5'\n","\n","cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n","                                verbose=1, save_best_only=True)\n","\n","cb_early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","\n","(X_train, Y_train), (X_validation, Y_validation) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n","X_validation = X_validation.reshape(X_validation.shape[0], 28, 28, 1).astype('float32') / 255\n","\n","Y_train = np_utils.to_categorical(Y_train, 10)\n","Y_validation = np_utils.to_categorical(Y_validation, 10)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","\n","history = model.fit(X_train, Y_train,\n","                    validation_data=(X_validation, Y_validation),\n","                    epochs=10, batch_size=200, verbose=0,\n","                    callbacks=[cb_checkpoint, cb_early_stopping])\n","\n","print('\\nAccuracy: {:.4f}'.format(model.evaluate(X_validation, Y_validation)[1]))\n","\n","y_vloss = history.history['val_loss']\n","y_loss = history.history['loss']\n","\n","x_len = numpy.arange(len(y_loss))\n","plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n","plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n","\n","plt.legend(loc='upper right')\n","plt.grid()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.show()\n","\n","keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)\n"],"execution_count":46,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-218e61100101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logs/fit/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"]}]}]}